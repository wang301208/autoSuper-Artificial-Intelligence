# AutoGPT æ•…éšœæ’é™¤æŒ‡å—

## æ¦‚è¿°

æœ¬æ–‡æ¡£æä¾›äº†AutoGPT v0.5.1å¸¸è§é—®é¢˜çš„è¯Šæ–­æ–¹æ³•å’Œè§£å†³æ–¹æ¡ˆï¼Œå¸®åŠ©å¼€å‘è€…å’Œè¿ç»´äººå‘˜å¿«é€Ÿå®šä½å’Œè§£å†³ç³»ç»Ÿé—®é¢˜ã€‚

## é—®é¢˜åˆ†ç±»

### ğŸš¨ ç´§æ€¥é—®é¢˜
- æœåŠ¡å®Œå…¨ä¸å¯ç”¨
- æ•°æ®ä¸¢å¤±æˆ–æŸå
- å®‰å…¨æ¼æ´æˆ–æ”»å‡»

### âš ï¸ é‡è¦é—®é¢˜
- æ€§èƒ½ä¸¥é‡ä¸‹é™
- éƒ¨åˆ†åŠŸèƒ½ä¸å¯ç”¨
- é¢‘ç¹é”™è¯¯æˆ–å¼‚å¸¸

### â„¹ï¸ ä¸€èˆ¬é—®é¢˜
- é…ç½®é—®é¢˜
- ä½¿ç”¨æ–¹æ³•é—®é¢˜
- æ€§èƒ½ä¼˜åŒ–å»ºè®®

## å¸¸è§é—®é¢˜åŠè§£å†³æ–¹æ¡ˆ

### 1. æœåŠ¡å¯åŠ¨é—®é¢˜

#### é—®é¢˜ï¼šå®¹å™¨å¯åŠ¨å¤±è´¥

**ç—‡çŠ¶**
```bash
docker: Error response from daemon: failed to create shim task
```

**è¯Šæ–­æ­¥éª¤**
```bash
# æ£€æŸ¥DockerçŠ¶æ€
docker info
docker system df

# æŸ¥çœ‹å®¹å™¨æ—¥å¿—
docker logs autogpt-container

# æ£€æŸ¥èµ„æºä½¿ç”¨
docker stats
free -h
df -h
```

**è§£å†³æ–¹æ¡ˆ**
```bash
# æ¸…ç†Dockerèµ„æº
docker system prune -a
docker volume prune

# é‡å¯DockeræœåŠ¡
sudo systemctl restart docker

# æ£€æŸ¥ç£ç›˜ç©ºé—´
sudo du -sh /var/lib/docker/*
```

#### é—®é¢˜ï¼šç«¯å£å†²çª

**ç—‡çŠ¶**
```
Error starting userland proxy: listen tcp4 0.0.0.0:8000: bind: address already in use
```

**è¯Šæ–­æ­¥éª¤**
```bash
# æŸ¥çœ‹ç«¯å£å ç”¨
netstat -tulpn | grep :8000
lsof -i :8000

# æŸ¥çœ‹è¿›ç¨‹ä¿¡æ¯
ps aux | grep autogpt
```

**è§£å†³æ–¹æ¡ˆ**
```bash
# æ–¹æ¡ˆ1ï¼šæ€æ­»å ç”¨è¿›ç¨‹
sudo kill -9 <PID>

# æ–¹æ¡ˆ2ï¼šä¿®æ”¹ç«¯å£é…ç½®
# ç¼–è¾‘ docker-compose.yml
ports:
  - "8001:8000"  # æ”¹ä¸ºå…¶ä»–ç«¯å£

# æ–¹æ¡ˆ3ï¼šä½¿ç”¨ç¯å¢ƒå˜é‡
export AP_SERVER_PORT=8001
```

#### é—®é¢˜ï¼šç¯å¢ƒå˜é‡é…ç½®é”™è¯¯

**ç—‡çŠ¶**
```
KeyError: 'OPENAI_API_KEY'
Configuration validation failed
```

**è¯Šæ–­æ­¥éª¤**
```bash
# æ£€æŸ¥ç¯å¢ƒå˜é‡
env | grep OPENAI
docker exec autogpt-container env | grep OPENAI

# æ£€æŸ¥é…ç½®æ–‡ä»¶
cat backend/autogpt/.env
```

**è§£å†³æ–¹æ¡ˆ**
```bash
# åˆ›å»ºæ­£ç¡®çš„ç¯å¢ƒé…ç½®
cp backend/autogpt/.env.example backend/autogpt/.env

# ç¼–è¾‘é…ç½®æ–‡ä»¶
vim backend/autogpt/.env

# å¿…éœ€çš„ç¯å¢ƒå˜é‡
OPENAI_API_KEY=your-api-key-here
DATABASE_STRING=postgresql://user:pass@host:5432/db
REDIS_HOST=redis
REDIS_PORT=6379

# é‡å¯æœåŠ¡
docker-compose restart autogpt
```

### 2. æ•°æ®åº“è¿æ¥é—®é¢˜

#### é—®é¢˜ï¼šPostgreSQLè¿æ¥å¤±è´¥

**ç—‡çŠ¶**
```
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) could not connect to server
```

**è¯Šæ–­æ­¥éª¤**
```bash
# æ£€æŸ¥PostgreSQLçŠ¶æ€
docker exec postgres pg_isready -U autogpt

# æµ‹è¯•è¿æ¥
docker exec postgres psql -U autogpt -d autogpt -c "SELECT 1;"

# æ£€æŸ¥ç½‘ç»œè¿æ¥
docker network ls
docker network inspect autogpt_default
```

**è§£å†³æ–¹æ¡ˆ**
```bash
# é‡å¯PostgreSQL
docker-compose restart postgres

# æ£€æŸ¥æ•°æ®åº“é…ç½®
docker exec postgres psql -U postgres -c "\l"

# é‡æ–°åˆ›å»ºæ•°æ®åº“
docker exec postgres createdb -U postgres autogpt

# è¿è¡Œæ•°æ®åº“è¿ç§»
docker exec autogpt-container poetry run alembic upgrade head
```

#### é—®é¢˜ï¼šæ•°æ®åº“è¿ç§»å¤±è´¥

**ç—‡çŠ¶**
```
alembic.util.exc.CommandError: Target database is not up to date
```

**è¯Šæ–­æ­¥éª¤**
```bash
# æ£€æŸ¥è¿ç§»çŠ¶æ€
docker exec autogpt-container poetry run alembic current
docker exec autogpt-container poetry run alembic history

# æ£€æŸ¥æ•°æ®åº“è¡¨
docker exec postgres psql -U autogpt -d autogpt -c "\dt"
```

**è§£å†³æ–¹æ¡ˆ**
```bash
# é‡ç½®æ•°æ®åº“ï¼ˆæ³¨æ„ï¼šä¼šä¸¢å¤±æ•°æ®ï¼‰
docker exec postgres psql -U autogpt -d autogpt -c "DROP SCHEMA public CASCADE; CREATE SCHEMA public;"

# é‡æ–°è¿è¡Œè¿ç§»
docker exec autogpt-container poetry run alembic upgrade head

# æˆ–è€…æ‰‹åŠ¨ä¿®å¤è¿ç§»
docker exec autogpt-container poetry run alembic stamp head
docker exec autogpt-container poetry run alembic upgrade head
```

### 3. Redisè¿æ¥é—®é¢˜

#### é—®é¢˜ï¼šRedisè¿æ¥è¶…æ—¶

**ç—‡çŠ¶**
```
redis.exceptions.ConnectionError: Error connecting to Redis
```

**è¯Šæ–­æ­¥éª¤**
```bash
# æ£€æŸ¥RedisçŠ¶æ€
docker exec redis redis-cli ping

# æ£€æŸ¥Redisé…ç½®
docker exec redis redis-cli config get "*"

# æµ‹è¯•è¿æ¥
docker exec autogpt-container python -c "import redis; r=redis.Redis(host='redis'); print(r.ping())"
```

**è§£å†³æ–¹æ¡ˆ**
```bash
# é‡å¯Redis
docker-compose restart redis

# æ¸…ç†Redisæ•°æ®ï¼ˆå¦‚æœéœ€è¦ï¼‰
docker exec redis redis-cli flushall

# æ£€æŸ¥å†…å­˜ä½¿ç”¨
docker exec redis redis-cli info memory
```

### 4. OpenAI APIé—®é¢˜

#### é—®é¢˜ï¼šAPIå¯†é’¥æ— æ•ˆ

**ç—‡çŠ¶**
```
openai.error.AuthenticationError: Incorrect API key provided
```

**è¯Šæ–­æ­¥éª¤**
```bash
# æ£€æŸ¥APIå¯†é’¥æ ¼å¼
echo $OPENAI_API_KEY | wc -c  # åº”è¯¥æ˜¯51ä¸ªå­—ç¬¦

# æµ‹è¯•APIå¯†é’¥
curl -H "Authorization: Bearer $OPENAI_API_KEY" \
     https://api.openai.com/v1/models
```

**è§£å†³æ–¹æ¡ˆ**
```bash
# æ›´æ–°APIå¯†é’¥
export OPENAI_API_KEY=sk-your-new-api-key

# é‡å¯æœåŠ¡
docker-compose restart autogpt

# éªŒè¯é…ç½®
docker exec autogpt-container python -c "
import openai
openai.api_key = 'your-api-key'
print(openai.Model.list())
"
```

#### é—®é¢˜ï¼šAPIé…é¢è¶…é™

**ç—‡çŠ¶**
```
openai.error.RateLimitError: You exceeded your current quota
```

**è¯Šæ–­æ­¥éª¤**
```bash
# æ£€æŸ¥APIä½¿ç”¨æƒ…å†µ
curl -H "Authorization: Bearer $OPENAI_API_KEY" \
     https://api.openai.com/v1/usage

# æŸ¥çœ‹åº”ç”¨æ—¥å¿—ä¸­çš„APIè°ƒç”¨
docker logs autogpt-container | grep "openai"
```

**è§£å†³æ–¹æ¡ˆ**
```bash
# è®¾ç½®ä½¿ç”¨é™åˆ¶
export OPENAI_MAX_TOKENS_PER_DAY=10000
export OPENAI_MAX_REQUESTS_PER_MINUTE=60

# ä½¿ç”¨æ›´ä¾¿å®œçš„æ¨¡å‹
export SMART_LLM=gpt-3.5-turbo
export FAST_LLM=gpt-3.5-turbo

# å®ç°è¯·æ±‚ç¼“å­˜
export ENABLE_RESPONSE_CACHE=true
export CACHE_TTL=3600
```

### 5. æ€§èƒ½é—®é¢˜

#### é—®é¢˜ï¼šå“åº”æ—¶é—´è¿‡é•¿

**ç—‡çŠ¶**
- APIå“åº”æ—¶é—´è¶…è¿‡30ç§’
- ä»»åŠ¡æ‰§è¡Œç¼“æ…¢
- ç”¨æˆ·ç•Œé¢å¡é¡¿

**è¯Šæ–­æ­¥éª¤**
```bash
# æ£€æŸ¥ç³»ç»Ÿèµ„æº
htop
iotop
nethogs

# æ£€æŸ¥æ•°æ®åº“æ€§èƒ½
docker exec postgres psql -U autogpt -d autogpt -c "
SELECT query, mean_exec_time, calls 
FROM pg_stat_statements 
ORDER BY mean_exec_time DESC 
LIMIT 10;"

# æ£€æŸ¥Redisæ€§èƒ½
docker exec redis redis-cli --latency-history

# åˆ†æåº”ç”¨æ—¥å¿—
docker logs autogpt-container | grep -E "(slow|timeout|error)"
```

**è§£å†³æ–¹æ¡ˆ**
```bash
# ä¼˜åŒ–æ•°æ®åº“
docker exec postgres psql -U autogpt -d autogpt -c "
CREATE INDEX CONCURRENTLY idx_tasks_status ON tasks(status);
CREATE INDEX CONCURRENTLY idx_tasks_created_at ON tasks(created_at);
VACUUM ANALYZE;
"

# å¢åŠ èµ„æºé™åˆ¶
# ç¼–è¾‘ docker-compose.yml
services:
  autogpt:
    deploy:
      resources:
        limits:
          memory: 4G
          cpus: '2.0'

# å¯ç”¨ç¼“å­˜
export ENABLE_MEMORY_CACHE=true
export CACHE_SIZE=1000

# è°ƒæ•´å¹¶å‘è®¾ç½®
export MAX_CONCURRENT_TASKS=5
export WORKER_PROCESSES=4
```

#### é—®é¢˜ï¼šå†…å­˜æ³„æ¼

**ç—‡çŠ¶**
```
MemoryError: Unable to allocate memory
Container killed due to OOM
```

**è¯Šæ–­æ­¥éª¤**
```bash
# ç›‘æ§å†…å­˜ä½¿ç”¨
docker stats autogpt-container

# æ£€æŸ¥Pythonå†…å­˜ä½¿ç”¨
docker exec autogpt-container python -c "
import psutil
import os
process = psutil.Process(os.getpid())
print(f'Memory: {process.memory_info().rss / 1024 / 1024:.2f} MB')
"

# åˆ†æå†…å­˜æ³„æ¼
docker exec autogpt-container python -m memory_profiler your_script.py
```

**è§£å†³æ–¹æ¡ˆ**
```bash
# è®¾ç½®å†…å­˜é™åˆ¶
docker run --memory=2g autogpt:latest

# å¯ç”¨åƒåœ¾å›æ”¶
export PYTHONHASHSEED=0
export PYTHONUNBUFFERED=1

# å®šæœŸé‡å¯æœåŠ¡
# æ·»åŠ åˆ°crontab
0 2 * * * docker-compose restart autogpt
```

### 6. ç½‘ç»œé—®é¢˜

#### é—®é¢˜ï¼šå¤–éƒ¨APIè®¿é—®å¤±è´¥

**ç—‡çŠ¶**
```
requests.exceptions.ConnectionError: Failed to establish a new connection
```

**è¯Šæ–­æ­¥éª¤**
```bash
# æµ‹è¯•ç½‘ç»œè¿æ¥
docker exec autogpt-container ping google.com
docker exec autogpt-container nslookup api.openai.com

# æ£€æŸ¥é˜²ç«å¢™è®¾ç½®
sudo ufw status
sudo iptables -L

# æµ‹è¯•HTTPè¿æ¥
docker exec autogpt-container curl -I https://api.openai.com
```

**è§£å†³æ–¹æ¡ˆ**
```bash
# é…ç½®ä»£ç†ï¼ˆå¦‚æœéœ€è¦ï¼‰
export HTTP_PROXY=http://proxy.company.com:8080
export HTTPS_PROXY=http://proxy.company.com:8080

# é…ç½®DNS
echo "nameserver 8.8.8.8" >> /etc/resolv.conf

# æ£€æŸ¥SSLè¯ä¹¦
docker exec autogpt-container python -c "
import ssl
import socket
context = ssl.create_default_context()
with socket.create_connection(('api.openai.com', 443)) as sock:
    with context.wrap_socket(sock, server_hostname='api.openai.com') as ssock:
        print(ssock.version())
"
```

### 7. å‰ç«¯é—®é¢˜

#### é—®é¢˜ï¼šFlutteråº”ç”¨æ— æ³•è¿æ¥åç«¯

**ç—‡çŠ¶**
```
DioError [DioErrorType.connectTimeout]: Connecting timeout
```

**è¯Šæ–­æ­¥éª¤**
```bash
# æ£€æŸ¥åç«¯æœåŠ¡çŠ¶æ€
curl http://localhost:8000/health

# æ£€æŸ¥ç½‘ç»œé…ç½®
flutter doctor
flutter config

# æŸ¥çœ‹Flutteræ—¥å¿—
flutter logs
```

**è§£å†³æ–¹æ¡ˆ**
```bash
# æ›´æ–°APIç«¯ç‚¹é…ç½®
# ç¼–è¾‘ frontend/lib/config/api_config.dart
const String baseUrl = 'http://localhost:8000';

# é‡æ–°æ„å»ºåº”ç”¨
flutter clean
flutter pub get
flutter run

# é…ç½®CORSï¼ˆåç«¯ï¼‰
export AP_SERVER_CORS_ALLOWED_ORIGINS=http://localhost:3000,http://localhost:5000
```

## æ—¥å¿—åˆ†æ

### æ—¥å¿—çº§åˆ«å’Œæ ¼å¼

```python
# é…ç½®æ—¥å¿—çº§åˆ«
export LOG_LEVEL=DEBUG  # DEBUG, INFO, WARNING, ERROR, CRITICAL

# æ—¥å¿—æ ¼å¼
export LOG_FORMAT=json  # json, simple, detailed
```

### å…³é”®æ—¥å¿—æ¨¡å¼

```bash
# é”™è¯¯æ—¥å¿—
docker logs autogpt-container 2>&1 | grep -i error

# æ€§èƒ½æ—¥å¿—
docker logs autogpt-container 2>&1 | grep -E "(slow|timeout|duration)"

# APIè°ƒç”¨æ—¥å¿—
docker logs autogpt-container 2>&1 | grep -E "(openai|api_call)"

# ä»»åŠ¡æ‰§è¡Œæ—¥å¿—
docker logs autogpt-container 2>&1 | grep -E "(task_|execute_)"
```

### æ—¥å¿—èšåˆå’Œåˆ†æ

```yaml
# filebeat.yml
filebeat.inputs:
- type: container
  paths:
    - '/var/lib/docker/containers/*/*.log'
  processors:
  - add_docker_metadata:
      host: "unix:///var/run/docker.sock"

output.elasticsearch:
  hosts: ["elasticsearch:9200"]
  index: "autogpt-logs-%{+yyyy.MM.dd}"

# logstash.conf
input {
  beats {
    port => 5044
  }
}

filter {
  if [container][name] == "autogpt" {
    json {
      source => "message"
    }
    
    if [level] == "ERROR" {
      mutate {
        add_tag => ["error"]
      }
    }
  }
}

output {
  elasticsearch {
    hosts => ["elasticsearch:9200"]
    index => "autogpt-logs-%{+yyyy.MM.dd}"
  }
}
```

## ç›‘æ§å’Œå‘Šè­¦

### å…³é”®æŒ‡æ ‡ç›‘æ§

```python
# PrometheusæŒ‡æ ‡
from prometheus_client import Counter, Histogram, Gauge

# é”™è¯¯ç‡ç›‘æ§
ERROR_COUNTER = Counter('autogpt_errors_total', 'Total errors', ['error_type'])

# å“åº”æ—¶é—´ç›‘æ§
RESPONSE_TIME = Histogram('autogpt_response_time_seconds', 'Response time')

# èµ„æºä½¿ç”¨ç›‘æ§
MEMORY_USAGE = Gauge('autogpt_memory_usage_bytes', 'Memory usage')
CPU_USAGE = Gauge('autogpt_cpu_usage_percent', 'CPU usage')

# ä¸šåŠ¡æŒ‡æ ‡ç›‘æ§
ACTIVE_TASKS = Gauge('autogpt_active_tasks', 'Number of active tasks')
TASK_SUCCESS_RATE = Histogram('autogpt_task_success_rate', 'Task success rate')
```

### å‘Šè­¦è§„åˆ™

```yaml
# prometheus-alerts.yml
groups:
- name: autogpt
  rules:
  - alert: AutoGPTHighErrorRate
    expr: rate(autogpt_errors_total[5m]) > 0.1
    for: 2m
    labels:
      severity: warning
    annotations:
      summary: "AutoGPT error rate is high"
      description: "Error rate is {{ $value }} errors per second"

  - alert: AutoGPTHighMemoryUsage
    expr: autogpt_memory_usage_bytes / (1024*1024*1024) > 1.5
    for: 5m
    labels:
      severity: warning
    annotations:
      summary: "AutoGPT memory usage is high"
      description: "Memory usage is {{ $value }}GB"

  - alert: AutoGPTServiceDown
    expr: up{job="autogpt"} == 0
    for: 1m
    labels:
      severity: critical
    annotations:
      summary: "AutoGPT service is down"
      description: "AutoGPT service has been down for more than 1 minute"
```

## æ€§èƒ½è°ƒä¼˜

### æ•°æ®åº“ä¼˜åŒ–

```sql
-- åˆ›å»ºå¿…è¦çš„ç´¢å¼•
CREATE INDEX CONCURRENTLY idx_tasks_status_created ON tasks(status, created_at);
CREATE INDEX CONCURRENTLY idx_agents_status ON agents(status);
CREATE INDEX CONCURRENTLY idx_steps_task_id ON steps(task_id);

-- åˆ†æè¡¨ç»Ÿè®¡ä¿¡æ¯
ANALYZE tasks;
ANALYZE agents;
ANALYZE steps;

-- ä¼˜åŒ–æŸ¥è¯¢
EXPLAIN ANALYZE SELECT * FROM tasks WHERE status = 'running' ORDER BY created_at DESC LIMIT 10;

-- é…ç½®å‚æ•°ä¼˜åŒ–
ALTER SYSTEM SET shared_buffers = '256MB';
ALTER SYSTEM SET effective_cache_size = '1GB';
ALTER SYSTEM SET work_mem = '4MB';
SELECT pg_reload_conf();
```

### åº”ç”¨ä¼˜åŒ–

```python
# è¿æ¥æ± é…ç½®
from sqlalchemy import create_engine
from sqlalchemy.pool import QueuePool

engine = create_engine(
    DATABASE_URL,
    poolclass=QueuePool,
    pool_size=20,
    max_overflow=30,
    pool_pre_ping=True,
    pool_recycle=3600
)

# å¼‚æ­¥ä¼˜åŒ–
import asyncio
from concurrent.futures import ThreadPoolExecutor

class OptimizedTaskProcessor:
    def __init__(self):
        self.executor = ThreadPoolExecutor(max_workers=10)
        self.semaphore = asyncio.Semaphore(5)
    
    async def process_task(self, task):
        async with self.semaphore:
            loop = asyncio.get_event_loop()
            return await loop.run_in_executor(
                self.executor, 
                self._sync_process_task, 
                task
            )

# ç¼“å­˜ä¼˜åŒ–
from functools import lru_cache
import redis

redis_client = redis.Redis(host='redis', port=6379, db=0)

@lru_cache(maxsize=1000)
def get_cached_result(key: str):
    result = redis_client.get(key)
    if result:
        return json.loads(result)
    return None

def set_cached_result(key: str, value: dict, ttl: int = 3600):
    redis_client.setex(key, ttl, json.dumps(value))
```

## å¤‡ä»½å’Œæ¢å¤

### æ•°æ®å¤‡ä»½

```bash
#!/bin/bash
# backup.sh

BACKUP_DIR="/backups"
DATE=$(date +%Y%m%d_%H%M%S)

# æ•°æ®åº“å¤‡ä»½
docker exec postgres pg_dump -U autogpt autogpt > "$BACKUP_DIR/db_backup_$DATE.sql"

# æ–‡ä»¶å¤‡ä»½
docker exec autogpt-container tar -czf - /app/data > "$BACKUP_DIR/files_backup_$DATE.tar.gz"

# Rediså¤‡ä»½
docker exec redis redis-cli --rdb - > "$BACKUP_DIR/redis_backup_$DATE.rdb"

# ä¸Šä¼ åˆ°äº‘å­˜å‚¨
aws s3 cp "$BACKUP_DIR/" s3://autogpt-backups/ --recursive

# æ¸…ç†æ—§å¤‡ä»½ï¼ˆä¿ç•™7å¤©ï¼‰
find "$BACKUP_DIR" -name "*.sql" -mtime +7 -delete
find "$BACKUP_DIR" -name "*.tar.gz" -mtime +7 -delete
find "$BACKUP_DIR" -name "*.rdb" -mtime +7 -delete
```

### æ•°æ®æ¢å¤

```bash
#!/bin/bash
# restore.sh

BACKUP_FILE=$1

if [ -z "$BACKUP_FILE" ]; then
    echo "Usage: $0 <backup_file>"
    exit 1
fi

# åœæ­¢æœåŠ¡
docker-compose stop autogpt

# æ¢å¤æ•°æ®åº“
docker exec postgres psql -U autogpt -d autogpt -c "DROP SCHEMA public CASCADE; CREATE SCHEMA public;"
docker exec -i postgres psql -U autogpt autogpt < "$BACKUP_FILE"

# æ¢å¤æ–‡ä»¶
docker exec autogpt-container rm -rf /app/data
docker exec -i autogpt-container tar -xzf - -C / < "files_backup_*.tar.gz"

# å¯åŠ¨æœåŠ¡
docker-compose start autogpt

echo "Restore completed successfully"
```

## å®‰å…¨é—®é¢˜å¤„ç†

### å®‰å…¨äº‹ä»¶å“åº”

```bash
# 1. ç«‹å³éš”ç¦»å—å½±å“çš„æœåŠ¡
docker-compose stop autogpt

# 2. æ”¶é›†æ—¥å¿—å’Œè¯æ®
docker logs autogpt-container > security_incident_$(date +%Y%m%d_%H%M%S).log
docker exec postgres pg_dump -U autogpt autogpt > security_backup_$(date +%Y%m%d_%H%M%S).sql

# 3. åˆ†ææ”»å‡»å‘é‡
grep -i "attack\|injection\|malicious" security_incident_*.log

# 4. æ›´æ–°å®‰å…¨é…ç½®
export EXECUTE_LOCAL_COMMANDS=false
export RESTRICT_TO_WORKSPACE=true
export SHELL_COMMAND_CONTROL=denylist

# 5. é‡æ–°éƒ¨ç½²å®‰å…¨ç‰ˆæœ¬
docker-compose up -d autogpt
```

### å®‰å…¨åŠ å›ºæ£€æŸ¥æ¸…å•

- [ ] æ›´æ–°æ‰€æœ‰ä¾èµ–åˆ°æœ€æ–°ç‰ˆæœ¬
- [ ] å¯ç”¨HTTPSå’ŒSSLè¯ä¹¦
- [ ] é…ç½®é˜²ç«å¢™è§„åˆ™
- [ ] å¯ç”¨è®¿é—®æ—¥å¿—å’Œå®¡è®¡
- [ ] è®¾ç½®å¼ºå¯†ç ç­–ç•¥
- [ ] å¯ç”¨å¤šå› ç´ è®¤è¯
- [ ] å®šæœŸå®‰å…¨æ‰«æ
- [ ] å¤‡ä»½åŠ å¯†å­˜å‚¨

## è”ç³»æ”¯æŒ

### é—®é¢˜æŠ¥å‘Šæ¨¡æ¿

```markdown
## é—®é¢˜æè¿°
ç®€è¦æè¿°é‡åˆ°çš„é—®é¢˜

## ç¯å¢ƒä¿¡æ¯
- AutoGPTç‰ˆæœ¬: v0.5.1
- æ“ä½œç³»ç»Ÿ: Ubuntu 20.04
- Dockerç‰ˆæœ¬: 20.10.21
- Pythonç‰ˆæœ¬: 3.10.12

## é‡ç°æ­¥éª¤
1. æ­¥éª¤1
2. æ­¥éª¤2
3. æ­¥éª¤3

## æœŸæœ›ç»“æœ
æè¿°æœŸæœ›çš„æ­£å¸¸è¡Œä¸º

## å®é™…ç»“æœ
æè¿°å®é™…å‘ç”Ÿçš„æƒ…å†µ

## é”™è¯¯æ—¥å¿—
```
ç²˜è´´ç›¸å…³çš„é”™è¯¯æ—¥å¿—
```

## å·²å°è¯•çš„è§£å†³æ–¹æ¡ˆ
åˆ—å‡ºå·²ç»å°è¯•è¿‡çš„è§£å†³æ–¹æ³•

## é™„åŠ ä¿¡æ¯
å…¶ä»–å¯èƒ½æœ‰ç”¨çš„ä¿¡æ¯
```

### è·å–å¸®åŠ©çš„æ¸ é“

- **GitHub Issues**: https://github.com/Significant-Gravitas/AutoGPT/issues
- **Discordç¤¾åŒº**: https://discord.gg/autogpt
- **æ–‡æ¡£ç½‘ç«™**: https://docs.agpt.co/
- **Stack Overflow**: æ ‡ç­¾ `autogpt`

### ç´§æ€¥æ”¯æŒ

å¯¹äºç”Ÿäº§ç¯å¢ƒçš„ç´§æ€¥é—®é¢˜ï¼š
1. ç«‹å³éš”ç¦»é—®é¢˜æœåŠ¡
2. æ”¶é›†å¿…è¦çš„æ—¥å¿—å’Œä¿¡æ¯
3. é€šè¿‡å®˜æ–¹æ¸ é“æŠ¥å‘Šé—®é¢˜
4. å®æ–½ä¸´æ—¶è§£å†³æ–¹æ¡ˆ
5. ç­‰å¾…å®˜æ–¹ä¿®å¤æˆ–æŒ‡å¯¼

è¿™ä¸ªæ•…éšœæ’é™¤æŒ‡å—æ¶µç›–äº†AutoGPTç³»ç»Ÿå¯èƒ½é‡åˆ°çš„å„ç§é—®é¢˜å’Œè§£å†³æ–¹æ¡ˆï¼Œå¸®åŠ©ç”¨æˆ·å¿«é€Ÿå®šä½å’Œè§£å†³é—®é¢˜ã€‚